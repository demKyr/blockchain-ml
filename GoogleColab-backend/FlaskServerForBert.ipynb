{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28552,"status":"ok","timestamp":1655456311116,"user":{"displayName":"Dimitrios Kyriakou","userId":"02878596377155728296"},"user_tz":-180},"id":"dY3DuQU_IbY3","outputId":"5073d0ee-ec85-4483-a5b7-21748fad3266"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21085,"status":"ok","timestamp":1655456332196,"user":{"displayName":"Dimitrios Kyriakou","userId":"02878596377155728296"},"user_tz":-180},"id":"KISCdlM5Ih6W","outputId":"8e84198d-2d76-4c39-c29b-ac2fa9a53d69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 35.7 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 59.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (1.1.4)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask) (2.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask-ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask-cors\n","  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask-cors) (1.1.4)\n","Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors) (1.15.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.9->flask-cors) (2.0.1)\n","Installing collected packages: flask-cors\n","Successfully installed flask-cors-3.0.10\n"]}],"source":["! pip install transformers\n","! pip install flask\n","! pip install flask-ngrok\n","! pip install -U flask-cors"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1655456332197,"user":{"displayName":"Dimitrios Kyriakou","userId":"02878596377155728296"},"user_tz":-180},"id":"z0hOrGYFIuRP"},"outputs":[],"source":["# ! ngrok authtoken 29rA6VvxT2voCttRs1SXLztpfoK_3W93BncBB2LHHfXxVbfUj"]},{"cell_type":"code","source":["modelNames = [\"BERTModel-Twitter\", \"BERTModel-IMDB\", \"BERTModel-Emotions\"]\n","labels = [['Positive','Negative','Neutral'], ['Negative','Positive'], ['Sadness', 'Anger', 'Love', 'Surprise', 'Fear', 'Happiness']]"],"metadata":{"id":"XndQhNiIEJb_","executionInfo":{"status":"ok","timestamp":1655456332198,"user_tz":-180,"elapsed":16,"user":{"displayName":"Dimitrios Kyriakou","userId":"02878596377155728296"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":844,"referenced_widgets":["9d6faeb891174b0ea8f30303de37289a","63609a77b4ff44c2857de9bbae4f587f","fb88d11ed53245ee846e00af7d0f5611","86c8a1519e694814a8c4c184b2e819c0","66950d9e82614ee4b2dba9150005b548","bb93cd65e71c4c3491ac96833db88995","706105c4f64345aa84180ef638ff2072","1a4706da96984549a69914728949394c","ee81746202e24798952bb1944da2d1b8","a4c83b6ec5fe4498bde8341c285bf7d3","44c09754415c4745a74278b3d54b761c","13b4befcec324a70a2638d7eda45ce09","4f5661b9205f4e5394ff637fca1b8dc4","29bbe6595cde4fc7a851ae3914bff4e8","83b177d5821d4f99b9764408eaa50940","11d9ab13c9774ca69b76f1ff28610b88","1664b5b432dc464287cd9cd49430e252","3d7592e919b34284ba505ade9d01b275","208346b07d67460dbe1517c7e4961f30","479358d1fdc146b4a47b3be99e6b0bc8","ff8721f524e846c9abc54b4d7524ee9a","d5d3d8bd6cb34651a66e3b5215c1c0ed","961d21d330984fadb3217c4ff429ccf1","e3b5ce1ad3d643c2b572dd0ccec35c74","e4f234f7efc34555b47bf95fc3bce9c3","570df48dc1be41278e812b676066d519","ce0663e46ae34d049f15b5cfed6816ee","a242f67217c440d58b5c7461feb286e8","583c813778d6487c99578376af71e830","857db475c8034566b0fc4e83c077bd91","e133c93677664e4ebbaa0f8a55895294","0b1b96f4545f4ad38643fd8af6a6a3a9","44bfd007d783457294206fd13d7c7446"]},"id":"Bxvkr5cFIklI","outputId":"064a4b04-2ed8-4587-8af8-6d1867e9d2cb","executionInfo":{"status":"ok","timestamp":1655457730544,"user_tz":-180,"elapsed":1398362,"user":{"displayName":"Dimitrios Kyriakou","userId":"02878596377155728296"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 BERTModel-Twitter\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d6faeb891174b0ea8f30303de37289a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b4befcec324a70a2638d7eda45ce09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"961d21d330984fadb3217c4ff429ccf1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at /content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/BERTModel-Twitter were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/BERTModel-Twitter.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["1 BERTModel-IMDB\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at /content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/BERTModel-IMDB were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/BERTModel-IMDB.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["2 BERTModel-Emotions\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at /content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/BERTModel-Emotions were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n","- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/BERTModel-Emotions.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Server Running🚀\n"," * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://dc6d-34-143-238-183.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["127.0.0.1 - - [17/Jun/2022 09:01:10] \"\u001b[37mPOST /test?model=0 HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [17/Jun/2022 09:01:12] \"\u001b[37mPOST /test?model=1 HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [17/Jun/2022 09:01:13] \"\u001b[37mPOST /test?model=2 HTTP/1.1\u001b[0m\" 200 -\n"]},{"output_type":"stream","name":"stdout","text":["Starting Training\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2/2 [==============================] - 49s 27s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.7668\n","Epoch 2/2\n","2/2 [==============================] - 24s 24s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9380 - val_accuracy: 0.7650\n"]},{"output_type":"stream","name":"stderr","text":["127.0.0.1 - - [17/Jun/2022 09:15:23] \"\u001b[37mPOST /train?model=0 HTTP/1.1\u001b[0m\" 200 -\n"]},{"output_type":"stream","name":"stdout","text":["Starting Evaluation\n","86/86 [==============================] - 27s 283ms/step - loss: 0.9942 - accuracy: 0.7569\n"]},{"output_type":"stream","name":"stderr","text":["127.0.0.1 - - [17/Jun/2022 09:15:52] \"\u001b[37mGET /evaluate?model=0 HTTP/1.1\u001b[0m\" 200 -\n"]}],"source":["from flask import Flask, jsonify, request, Response\n","from flask_cors import CORS, cross_origin\n","from flask_ngrok import run_with_ngrok\n","\n","import json\n","\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, TFBertForSequenceClassification\n","from transformers import InputExample, InputFeatures\n","\n","\n","# model_save_name = 'BERTModel'\n","# path = F\"./NeuralNetwork/{model_save_name}\" \n","# model_save_name = 'BERTModel'\n","# path = F\"/content/gdrive/MyDrive/Colab_Notebooks/savedModels/{model_save_name}\" \n","# testSetPath = F\"/content/gdrive/MyDrive/Colab_Notebooks/savedModels/{model_save_name}-test.csv\"\n","# validationSetPath = F\"/content/gdrive/MyDrive/Colab_Notebooks/savedModels/{model_save_name}-validation.csv\"\n"," \n","\n","def loadModel(model_save_name):\n","    path = F\"/content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/{model_save_name}\" \n","    testSetPath = F\"/content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/{model_save_name}-test.csv\"\n","    validationSetPath = F\"/content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/{model_save_name}-validation.csv\"\n","\n","    # ## Load the BERT Classifier and Tokenizer along with Input modules\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","    # ## Load CSV, test and validation datasets\n","    # test = pd.read_csv('./NeuralNetwork/test.csv')\n","    # validation = pd.read_csv('./NeuralNetwork/validation.csv')\n","    test = pd.read_csv(testSetPath)\n","    validation = pd.read_csv(validationSetPath)\n","    test = test.iloc[: , 1:]\n","    validation = validation.iloc[: , 1:]\n","\n","    loaded_model = TFBertForSequenceClassification.from_pretrained(path, local_files_only=True)\n","\n","    return loaded_model,tokenizer,test,validation\n","\n","def convert_data_to_examples_single(inputDataset, DATA_COLUMN, LABEL_COLUMN): \n","    train_InputExamples = inputDataset.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n","                                                        text_a = x[DATA_COLUMN], \n","                                                        text_b = None,\n","                                                        label = x[LABEL_COLUMN]), axis = 1)  \n","    return train_InputExamples\n","\n","def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n","    features = [] # -> will hold InputFeatures to be converted later\n","\n","    for e in examples:\n","        # Documentation is really strong for this method, so please take a look at it\n","        input_dict = tokenizer.encode_plus(\n","            e.text_a,\n","            add_special_tokens=True,\n","            max_length=max_length, # truncates if len(s) > max_length\n","            return_token_type_ids=True,\n","            return_attention_mask=True,\n","            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n","            truncation=True\n","        )\n","\n","        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n","            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n","\n","        features.append(\n","            InputFeatures(\n","                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n","            )\n","        )\n","\n","    def gen():\n","        for f in features:\n","            yield (\n","                {\n","                    \"input_ids\": f.input_ids,\n","                    \"attention_mask\": f.attention_mask,\n","                    \"token_type_ids\": f.token_type_ids,\n","                },\n","                f.label,\n","            )\n","\n","    return tf.data.Dataset.from_generator(\n","        gen,\n","        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n","        (\n","            {\n","                \"input_ids\": tf.TensorShape([None]),\n","                \"attention_mask\": tf.TensorShape([None]),\n","                \"token_type_ids\": tf.TensorShape([None]),\n","            },\n","            tf.TensorShape([]),\n","        ),\n","    )\n","\n","def trainModel(loadedModel,tokenizer,validation,train,model_save_name):\n","\n","    path = F\"/content/gdrive/MyDrive/Colab Notebooks/ml-blockchain/savedModels/{model_save_name}\" \n","\n","    DATA_COLUMN = 'DATA_COLUMN'\n","    LABEL_COLUMN = 'LABEL_COLUMN'\n","\n","    validation_InputExamples = convert_data_to_examples_single(validation, DATA_COLUMN, LABEL_COLUMN)\n","    validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n","    validation_data = validation_data.batch(32)\n","\n","    train_InputExamples = convert_data_to_examples_single(train, DATA_COLUMN, LABEL_COLUMN)\n","    train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n","    train_data = train_data.batch(32).repeat(2)\n","\n","    # ## Retrain BERT model\n","    loadedModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","                metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n","\n","    loadedModel.fit(train_data, epochs=2, validation_data=validation_data)\n","\n","    # # model_save_name = 'BERTModel'\n","    # # path = F\"./NeuralNetwork/{model_save_name}\" \n","    # model_save_name = 'BERTModel1(2022-05-21 10:34)'\n","    # path = F\"/content/gdrive/MyDrive/Colab_Notebooks/savedModels/{model_save_name}\" \n","    loadedModel.save_pretrained(path)\n","\n","    return loadedModel\n","\n","def evaluateModel(loadedModel,tokenizer,test):\n","    DATA_COLUMN = 'DATA_COLUMN'\n","    LABEL_COLUMN = 'LABEL_COLUMN'\n","\n","    test_inputExamples = convert_data_to_examples_single(test, DATA_COLUMN, LABEL_COLUMN)\n","    test_data = convert_examples_to_tf_dataset(list(test_inputExamples), tokenizer)\n","    test_data = test_data.batch(32)\n","    \n","    loadedModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n","                metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n","\n","    evaluation = loadedModel.evaluate(test_data)\n","\n","    return (evaluation)\n","\n","def testModel(loadedModel,tokenizer,pred_sentences,labels):\n","\n","    tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n","    tf_outputs = loadedModel(tf_batch)\n","    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n","    # labels = ['Positive','Negative','Neutral']\n","    label = tf.argmax(tf_predictions, axis=1)\n","    label = label.numpy()\n","    return labels[label[0]]\n","\n","###################################################################################################################\n","\n","app = Flask(__name__)\n","\n","\n","run_with_ngrok(app)  \n","CORS(app)\n","\n","loadedModel = [None] * len(modelNames)\n","tokenizer = [None] * len(modelNames)\n","test = [None] * len(modelNames)\n","validation = [None] * len(modelNames)\n","\n","for id,modelName in enumerate(modelNames):\n","  print(id,modelName)\n","  loadedModel[id],tokenizer[id],test[id],validation[id] = loadModel(modelName)\n","\n","\n","@app.route('/train', methods=['POST'])\n","def trainFun():\n","    print('Starting Training')\n","    \n","    modelId = int(request.args.get('model'))\n","\n","    # trainSetInput = request.json\n","    trainSetInput = json.loads(request.data.decode('utf-8'))\n","\n","    trainDF = pd.DataFrame(trainSetInput)\n","    del trainDF['id']\n","    del trainDF['proposedLbl']\n","    del trainDF['goodData']\n","    trainDF.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n","    trainModel(loadedModel[modelId],tokenizer[modelId],validation[modelId],trainDF,modelNames[modelId])\n","    \n","    # response = Response(status=200)\n","    response = jsonify(status=\"ok\")\n","    return response\n","\n","\n","@app.route('/evaluate')\n","def evaluateFun():\n","    print('Starting Evaluation')\n","\n","    modelId = int(request.args.get('model'))\n","\n","    eval = evaluateModel(loadedModel[modelId],tokenizer[modelId],test[modelId])\n","    [loss,acc] = eval\n","\n","    response = jsonify(loss=loss,acc=acc)\n","    return response\n","\n","\n","@app.route('/test', methods=['POST'])\n","def testFun():\n","\n","    modelId = int(request.args.get('model'))\n","\n","    dataIn = json.loads(request.data.decode('utf-8'))\n","    pred_sent = dataIn['caption']\n","\n","    # pred_sent = request.json['caption']\n","    pred = testModel(loadedModel[modelId],tokenizer[modelId],pred_sent,labels[modelId])\n","\n","    response = jsonify(prediction=pred)\n","    return response\n","\n","\n","\n","\n","if (__name__ == \"__main__\"):\n","    print('Server Running🚀')\n","    app.run()\n","\n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"FlaskServerForBert.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"9d6faeb891174b0ea8f30303de37289a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63609a77b4ff44c2857de9bbae4f587f","IPY_MODEL_fb88d11ed53245ee846e00af7d0f5611","IPY_MODEL_86c8a1519e694814a8c4c184b2e819c0"],"layout":"IPY_MODEL_66950d9e82614ee4b2dba9150005b548"}},"63609a77b4ff44c2857de9bbae4f587f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb93cd65e71c4c3491ac96833db88995","placeholder":"​","style":"IPY_MODEL_706105c4f64345aa84180ef638ff2072","value":"Downloading: 100%"}},"fb88d11ed53245ee846e00af7d0f5611":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a4706da96984549a69914728949394c","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee81746202e24798952bb1944da2d1b8","value":231508}},"86c8a1519e694814a8c4c184b2e819c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4c83b6ec5fe4498bde8341c285bf7d3","placeholder":"​","style":"IPY_MODEL_44c09754415c4745a74278b3d54b761c","value":" 226k/226k [00:00&lt;00:00, 205kB/s]"}},"66950d9e82614ee4b2dba9150005b548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb93cd65e71c4c3491ac96833db88995":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706105c4f64345aa84180ef638ff2072":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a4706da96984549a69914728949394c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee81746202e24798952bb1944da2d1b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4c83b6ec5fe4498bde8341c285bf7d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44c09754415c4745a74278b3d54b761c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13b4befcec324a70a2638d7eda45ce09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f5661b9205f4e5394ff637fca1b8dc4","IPY_MODEL_29bbe6595cde4fc7a851ae3914bff4e8","IPY_MODEL_83b177d5821d4f99b9764408eaa50940"],"layout":"IPY_MODEL_11d9ab13c9774ca69b76f1ff28610b88"}},"4f5661b9205f4e5394ff637fca1b8dc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1664b5b432dc464287cd9cd49430e252","placeholder":"​","style":"IPY_MODEL_3d7592e919b34284ba505ade9d01b275","value":"Downloading: 100%"}},"29bbe6595cde4fc7a851ae3914bff4e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_208346b07d67460dbe1517c7e4961f30","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_479358d1fdc146b4a47b3be99e6b0bc8","value":28}},"83b177d5821d4f99b9764408eaa50940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff8721f524e846c9abc54b4d7524ee9a","placeholder":"​","style":"IPY_MODEL_d5d3d8bd6cb34651a66e3b5215c1c0ed","value":" 28.0/28.0 [00:00&lt;00:00, 840B/s]"}},"11d9ab13c9774ca69b76f1ff28610b88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1664b5b432dc464287cd9cd49430e252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d7592e919b34284ba505ade9d01b275":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"208346b07d67460dbe1517c7e4961f30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"479358d1fdc146b4a47b3be99e6b0bc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff8721f524e846c9abc54b4d7524ee9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d3d8bd6cb34651a66e3b5215c1c0ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"961d21d330984fadb3217c4ff429ccf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3b5ce1ad3d643c2b572dd0ccec35c74","IPY_MODEL_e4f234f7efc34555b47bf95fc3bce9c3","IPY_MODEL_570df48dc1be41278e812b676066d519"],"layout":"IPY_MODEL_ce0663e46ae34d049f15b5cfed6816ee"}},"e3b5ce1ad3d643c2b572dd0ccec35c74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a242f67217c440d58b5c7461feb286e8","placeholder":"​","style":"IPY_MODEL_583c813778d6487c99578376af71e830","value":"Downloading: 100%"}},"e4f234f7efc34555b47bf95fc3bce9c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_857db475c8034566b0fc4e83c077bd91","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e133c93677664e4ebbaa0f8a55895294","value":570}},"570df48dc1be41278e812b676066d519":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b1b96f4545f4ad38643fd8af6a6a3a9","placeholder":"​","style":"IPY_MODEL_44bfd007d783457294206fd13d7c7446","value":" 570/570 [00:00&lt;00:00, 20.1kB/s]"}},"ce0663e46ae34d049f15b5cfed6816ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a242f67217c440d58b5c7461feb286e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"583c813778d6487c99578376af71e830":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"857db475c8034566b0fc4e83c077bd91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e133c93677664e4ebbaa0f8a55895294":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b1b96f4545f4ad38643fd8af6a6a3a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44bfd007d783457294206fd13d7c7446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}